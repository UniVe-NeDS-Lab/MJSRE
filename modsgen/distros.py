# -*- coding: utf-8 -*-
"""
Created on Wed Oct 29 14:50:36 2025

@author: dile
"""
try:
    import cupy as cp
except ImportError:
    import numpy as cp


'''
This modules provides helper functions for loading simulation parameters
from text files and for generating random variates from various probability
distribution using cupy for GPU acceleration
'''

def bpar_parser(values):
    """
    Parses a line for Bounded Pareto distribution input parameters
    
    Expected line format: (size, prob, x_min, x_max, shape)
    """
    return {
        'sizes': int(values[0]),   # class server need
        'probs': float(values[1]), # class probability
        'xmins': float(values[2]), # lower bound
        'xmaxs': float(values[3]), # upper bound
        'shapes': float(values[4]) # alpha shape parameter
    }

def exp_parser(values): 
    """
    Parses a line for Exponential distrbution input parameters
    
    Computes the rate (mu) from the mean service time
    
    Expected line format: (size, prob, mean_time)
    """
    times = float(values[2]) # mean class service time
    return {
        'sizes': int(values[0]), # class server need
        'probs': float(values[1]), # class probability
        'mus': 1.0 / times if times != 0 else float('inf')
    }

def erlk_parser(values):
    """
    Parses a line for Erlang-k distrbution input parameters
    
    Computes the rate from the mean service time
    Note: the final Erlang rate will be (k * rate)
    
    Expected line format: (size, prob, mean_time, k)
    """
    times = float(values[2]) # mean class/phase service time
    
    return {
        'sizes': int(values[0]), # class server need
        'probs': float(values[1]), # class probability
        'rates': 1.0 / times if times != 0 else float('inf'),
        'ks': float(values[3]) # number of Erlang phases
    }

def hyperexp_parser(values):
    """
    Parses a line for Hypereponential distrbution input parameters
    
    Computes rates for each of the two phases from their mean times 
    
    Expeced line format: (size, prob, mean_time1, mean_time2, prob_phase1)
    """
    times1 = float(values[2]) # mean class service time for phase 1
    times2 = float(values[3]) # mean class service time for phase 2
    
    return {
        'sizes': int(values[0]), # class server need
        'probs': float(values[1]), # class probability
        'rates_ph1': 1.0 / times1 if times1 != 0 else float('inf'),
        'rates_ph2': 1.0 / times2 if times2 != 0 else float('inf'),
        'pphases': float(values[4]) # probability of choosing phase 1
    }

def load_params(input_txt, distro_parser):
    """
    Loads simulation parameters from a text file.

    This function reads a specified text file line by line and uses the
    provided `distro_parser` function to interpret each line. It aggregates
    the parameters from all lines into a dictionary of lists, which is then
    converted into a dictionary of CuPy arrays.

    Params:
        input_txt (str): The name of the input file (without .txt extension)
                         located in the 'inputs/' directory.
        distro_parser (callable): A function (e.g., `exp_parser`) that
                                  takes a list of string values from a line
                                  and returns a dictionary of parameters.

    Returns:
        Tuple[dict, int]:
            - A dictionary where keys are parameter names (e.g., 'sizes', 'probs')
              and values are CuPy arrays containing the data for all classes.
            - An integer (nClasses) count of the number of lines/classes loaded.
    """
    
    data_lists = {}
    nClasses = 0

    # read the txt file to retrieve params
    with open(f'inputs/{input_txt}.txt', 'r') as file:
        # read and process each line
        for line in file:
            # remove parentheses and split the line into values
            values = line.strip('()\n').split(', ')
            
            # use the provided parser function to process the line
            # with the input parameters
            parsed_data = distro_parser(values)

            # initialize lists in our dictionary on the first line
            if nClasses == 0:
                for key in parsed_data.keys():
                    data_lists[key] = []
            
            # append the parsed data to the correct lists
            for key, value in parsed_data.items():
                data_lists[key].append(value)
                
            nClasses += 1

    data_arrays = {key: cp.array(lst) for key, lst in data_lists.items()}
    
    return data_arrays, nClasses

def compute_sigmas_erlk(rng_sigma, class_indices, **params):
    """ 
    Generate Erlang-k distributed service times (sigmas) on the GPU using the 
    property that an Erlang variate can be generated by summing k independent
    Exponential variates.
    
    Params:
        rng_sigma (list[cp.ndarray]): List of uniform random arrays [0, 1).
                                      Length must equal `k_max`.
        class_indices (cp.ndarray): Array mapping arrivals to their class.
        **params (dict): Dictionary of parameter arrays (e.g., 'ks', 'rates').
    
    Returns:
        cp.ndarray: Array of Erlang-k distributed service times.
    """
    
    ks_row = params['ks'][class_indices]
    rates_row = params['rates'][class_indices]
    k_max = int(cp.max(params['ks'])) # takes max k
    
    # we assume sigma_rands_list has k_max arrays
    if len(rng_sigma) != k_max:
        # num_sigma_streams was wrong
        return cp.zeros_like(class_indices, dtype=cp.float32) 

    # stack all k random arrays: (k_max, Ntries, chunk_size)
    # and convert to (Ntries, chunk_size, k_max)
    all_rands = cp.stack(rng_sigma, axis=0).transpose((1, 2, 0))
    
    # broadcasting makes a (Ntries, chunk_size, k_max) mask
    mask = cp.arange(k_max) < ks_row[..., None]
    
    # calculate sigmas and apply mask, so we only sum the k relevant samples
    exp_samples = cp.where(mask, -cp.log(all_rands), 0)
    
    # sum along the k dimension
    sum_exp = exp_samples.sum(axis=2) # (Ntries, chunk_size)
    
    # divide by (k * rate) for each sample
    divisor = (ks_row * rates_row)
    sigmas = sum_exp / divisor
    
    return sigmas

def compute_sigmas_hyperexp(rng_sigma, class_indices, **params):
    """
    Generates Hyperexponential distributed service times (sigmas) on the GPU.

    Params:
        rng_sigma (list[cp.ndarray]): List of 2 uniform random arrays [0, 1).
        class_indices (cp.ndarray): Array mapping arrivals to their class.
        **params (dict): Dictionary of parameter arrays.
    
    Returns:
        cp.ndarray: Array of hyperexponentially distributed service times.
    """
     
    # needs two arrays: one for phase, one for the uniform sample
    phase_rand = rng_sigma[0]
    uniform_samples = rng_sigma[1]
    
    # get class-specific params 
    pph_row      = params['pphases'][class_indices]
    ratesph1_row = params['rates_ph1'][class_indices]
    ratesph2_row = params['rates_ph2'][class_indices]
    
    # select phase and rates entirely on GPU
    phase_selector = phase_rand < pph_row
    rates = cp.where(phase_selector, ratesph1_row, ratesph2_row)
    
    sigmas = -cp.log(uniform_samples) / rates
    return sigmas

def compute_sigmas_bpar(sigma_rands, class_indices, **params):
    
    """
    Generates Bounded Pareto distributed service times (sigmas) on the GPU.

    Params:
        rng_sigma (list[cp.ndarray]): List with 1 uniform random array [0, 1).
        class_indices (cp.ndarray): Array mapping arrivals to their class.
        **params (dict): Dictionary of parameter arrays ('xmins', 'xmaxs', 'shapes').
    
    Returns:
        cp.ndarray: Array of Bounded Pareto distributed service times.
    """
    
    unifs = sigma_rands[0] 
    
    dws = params['xmins'][class_indices]
    ups = params['xmaxs'][class_indices]
    shs = params['shapes'][class_indices]
    
    nums = (unifs * (ups**shs)) - (unifs * (dws**shs)) - (ups**shs)
    dens = (ups**shs) * (dws**shs)
    fracs = nums / dens

    sigmas = (-fracs)**(-1 / shs)
    return sigmas


def compute_sigmas_exp(sigma_rands, class_indices, **params):
    """
    Generates Exponentially distributed service times (sigmas) on the GPU.
    where `lambda` (the rate) is stored in the 'mus' parameter.

    Params:
        rng_sigma (list[cp.ndarray]): List with 1 uniform random array [0, 1).
        class_indices (cp.ndarray): Array mapping arrivals to their class.
        **params (dict): Dictionary containing 'mus' (the rates) array.
    
    Returns:
        cp.ndarray: Array of exponentially distributed service times.
    """
 
    # unpack parameters from the dictionary
    selected_mus = cp.asarray(params['mus'])[class_indices]
     
    sigmas = -cp.log(sigma_rands[0]) / selected_mus
    return sigmas
